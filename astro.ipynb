{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the images\n",
    "image_directory = './'  # Assuming images are in the current directory\n",
    "\n",
    "# Initialize a list to store image paths\n",
    "image_files = []\n",
    "\n",
    "# List all files in the directory and filter for image files\n",
    "for file_name in os.listdir(image_directory):\n",
    "    if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_files.append(os.path.join(image_directory, file_name))\n",
    "\n",
    "# Function to read and display images using OpenCV\n",
    "def read_and_display_images(image_paths):\n",
    "    for image_path in image_paths:\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            # Display the image\n",
    "            cv2.imshow('Image', image)\n",
    "            cv2.waitKey(1000)  # Display each image for 1 second\n",
    "        else:\n",
    "            print(f\"Failed to read image: {image_path}\")\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the list of image files\n",
    "read_and_display_images(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(image,title='',fig_sz=(16,12)):\n",
    "    plt.figure(figsize=fig_sz)\n",
    "    plt.imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channel(channel, title='', fig_sz = (16,12)):\n",
    "    plt.figure(figsize=fig_sz)\n",
    "    plt.imshow(channel, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first image in the list\n",
    "image = cv2.imread(image_files[9])\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "show_img(image_rgb,\"milky way og\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply median blur to each channel\n",
    "ks = 5\n",
    "b_channel = cv2.medianBlur(image[:, :, 0], ks)\n",
    "g_channel = cv2.medianBlur(image[:, :, 1], ks)\n",
    "r_channel = cv2.medianBlur(image[:, :, 2], ks)\n",
    "\n",
    "# Merge the channels back\n",
    "image_denoised = cv2.merge([r_channel, g_channel, b_channel])\n",
    "\n",
    "# Display the denoised color image\n",
    "show_img(image_denoised, 'Denoised Color Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsharp_masking(image,ks=9,sd=10,wt_original=1.5,wt_blurred=-0.5,scalar=0):\n",
    "    blurred = cv2.GaussianBlur(image, (ks, ks), sd)\n",
    "    sharpened = cv2.addWeighted(image, wt_original, blurred, wt_blurred, scalar)\n",
    "    r_channel, g_channel, b_channel = cv2.split(sharpened)\n",
    "    combined_image1 = cv2.merge((b_channel, g_channel, r_channel))\n",
    "    combined_image2 = cv2.merge((r_channel, g_channel, b_channel))\n",
    "    \n",
    "    show_img(combined_image1)\n",
    "    show_img(combined_image2)\n",
    "    \n",
    "    return [combined_image1,combined_image2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_image = unsharp_masking(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread(image_files[13])\n",
    "img21 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "show_img(img21)\n",
    "\n",
    "img22 = unsharp_masking(img21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_stars(proc_img_gray,threshold_value,show_imgs = False, figsz = (4,3)):\n",
    "    \n",
    "    _, thresholded_img = cv2.threshold(proc_img_gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned_image = cv2.morphologyEx(thresholded_img, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    cleaned_image = cv2.morphologyEx(cleaned_image, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    # Find contours of the stars\n",
    "    contours, _ = cv2.findContours(cleaned_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on the original binary image for visualization\n",
    "    contour_image = cv2.cvtColor(cleaned_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 1)\n",
    "\n",
    "    # Count the number of stars\n",
    "    num_stars = len(contours)\n",
    "    print(f\"Threshold: {threshold_value}, Number of stars detected: {num_stars}\")\n",
    "    \n",
    "    if show_imgs:\n",
    "        # Display the main, cleaned and contour image\n",
    "        show_img(thresholded_img,fig_sz=figsz)\n",
    "        show_img(cleaned_image, f'Cleaned Binary Image at threshold {threshold_value}', fig_sz=figsz)\n",
    "        show_img(contour_image, f'Star Contours at threshold {threshold_value}', fig_sz=figsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_img = img22[1]\n",
    "\n",
    "# Convert to grayscale if not already\n",
    "if len(proc_img.shape) == 3:\n",
    "    proc_img_gray = cv2.cvtColor(proc_img, cv2.COLOR_RGB2GRAY)\n",
    "else:\n",
    "    proc_img_gray = proc_img\n",
    "\n",
    "# Apply intensity thresholding\n",
    "threshold_values = [(i*16)-1 for i in range(4,9)]\n",
    "for threshold_value in threshold_values:\n",
    "    if threshold_value == min(threshold_values):\n",
    "        proc_stars(proc_img_gray,threshold_value,show_imgs=True,figsz=(8,6))\n",
    "    elif threshold_value == max(threshold_values):\n",
    "        proc_stars(proc_img_gray,threshold_value,show_imgs=True)\n",
    "    else:\n",
    "        proc_stars(proc_img_gray,threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [(i*16)-1 for i in range(1,17)]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Define the neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 5)  # 3 input features to 5 hidden nodes\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout with 50% probability\n",
    "        self.fc2 = nn.Linear(5, 2)  # 5 hidden nodes to 2 output nodes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation function\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc2(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Create the network\n",
    "net = SimpleNN()\n",
    "\n",
    "# Example input\n",
    "input_data = torch.randn(1, 3)  # Batch size of 1, 3 input features\n",
    "\n",
    "# Forward pass\n",
    "output_data = net(input_data)\n",
    "\n",
    "# Visualize the network\n",
    "make_dot(output_data, params=dict(net.named_parameters())).render(\"network\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Define the neural network\n",
    "class FashionMNISTNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # Input layer (28x28 pixels) to 128 hidden nodes\n",
    "        self.fc2 = nn.Linear(128, 64)  # Hidden layer to 64 hidden nodes\n",
    "        self.fc3 = nn.Linear(64, 10)  # Hidden layer to 10 output nodes (10 classes)\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout with 50% probability\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the input image\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = torch.relu(self.fc2(x))  # ReLU activation\n",
    "        x = self.fc3(x)  # Output layer\n",
    "        return x\n",
    "\n",
    "# Initialize the network\n",
    "net = FashionMNISTNN()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data/FashionMNIST', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Example input from the dataset\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)  # Use the next function to get a batch\n",
    "images = images[:1]  # Take a single example for visualization\n",
    "\n",
    "# Forward pass to visualize the network\n",
    "output = net(images)\n",
    "\n",
    "# Visualize the network\n",
    "make_dot(output, params=dict(net.named_parameters())).render(\"fashion_mnist_nn\", format=\"png\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):  # Loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        outputs = net(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(net.state_dict(), 'fashion_mnist_nn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Define the neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the input image\n",
    "    layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    layers.Dense(64, activation='relu'),  # Another hidden layer with ReLU activation\n",
    "    layers.Dense(10)  # Output layer with 10 nodes (one for each class)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# Save the model\n",
    "model.save('fashion_mnist_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "logdir = os.path.join(\"logs\", \"fashion_mnist\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model with TensorBoard callback\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Define the neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the input image\n",
    "    layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    layers.Dense(64, activation='relu'),  # Another hidden layer with ReLU activation\n",
    "    layers.Dense(10)  # Output layer with 10 nodes (one for each class)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up TensorBoard callback\n",
    "logdir = os.path.join(\"logs\", \"fashion_mnist\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model with TensorBoard callback\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# Save the model\n",
    "model.save('fashion_mnist_model.h5')\n",
    "\n",
    "# Save the model architecture as an image\n",
    "tf.keras.utils.plot_model(model, to_file='fashion_mnist_model.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "# hyperparameters:\n",
    "\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Define the neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Flatten the input image\n",
    "    layers.Dense(128, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    layers.Dense(64, activation='relu'),  # Another hidden layer with ReLU activation\n",
    "    layers.Dense(10)  # Output layer with 10 nodes (one for each class)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up TensorBoard callback\n",
    "logdir = os.path.join(\"logs\", \"fashion_mnist\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model with TensorBoard callback\n",
    "model.fit(x_train, y_train, epochs=25, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# Save the model\n",
    "model.save('fashion_mnist_model.h5')\n",
    "\n",
    "# Save the model architecture as an image\n",
    "tf.keras.utils.plot_model(model, to_file='fashion_mnist_model.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "# Load the FashionMNIST dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Reshape the data to include the channel dimension\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Define the Convolutional Neural Network model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # First convolutional layer\n",
    "    layers.MaxPooling2D((2, 2)),  # First max pooling layer\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),  # Second convolutional layer\n",
    "    layers.MaxPooling2D((2, 2)),  # Second max pooling layer\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),  # Third convolutional layer\n",
    "    layers.Flatten(),  # Flatten the 3D output to 1D\n",
    "    layers.Dense(128, activation='relu'),  # Fully connected layer with ReLU activation\n",
    "    layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    layers.Dense(10)  # Output layer with 10 nodes (one for each class)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Set up TensorBoard callback\n",
    "logdir = os.path.join(\"logs\", \"fashion_mnist\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model with TensorBoard callback\n",
    "model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "# Save the model\n",
    "model.save('fashion_mnist_cnn.h5')\n",
    "\n",
    "# Save the model architecture as an image\n",
    "tf.keras.utils.plot_model(model, to_file='fashion_mnist_cnn.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA support: False\n",
      "Built with GPU support: False\n",
      "Available physical devices:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "GPUs are not available.\n",
      "Detailed device information:\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3636850126378938361\n",
      "xla_global_id: -1\n",
      "]\n",
      "TensorFlow is using the CPU.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check if TensorFlow was built with CUDA (GPU) support\n",
    "print(\"Built with CUDA support:\", tf.test.is_built_with_cuda())\n",
    "print(\"Built with GPU support:\", tf.test.is_built_with_gpu_support())\n",
    "\n",
    "# List available physical devices\n",
    "print(\"Available physical devices:\")\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "for device in physical_devices:\n",
    "    print(device)\n",
    "\n",
    "# Check for GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPUs are available.\")\n",
    "    for gpu in gpus:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"GPUs are not available.\")\n",
    "\n",
    "# Check detailed device information\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"Detailed device information:\")\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# Check if TensorFlow is using the GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow is using the GPU.\")\n",
    "else:\n",
    "    print(\"TensorFlow is using the CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "eg = egs.split('\\n')\n",
    "data = [line.split('\\t') for line in eg]\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "print(len(df))\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg2 = egs2.split('\\n')\n",
    "data2 = [line.split('\\t') for line in eg]\n",
    "df2 = pd.DataFrame(data2[1:], columns=data2[0])\n",
    "df_combined = pd.concat([df, df2]).drop_duplicates().reset_index(drop=True)\n",
    "print(len(df_combined))\n",
    "print(df_combined.to_string())\n",
    "df_combined.to_csv(\"examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "del egs, eg, data, df, egs2, eg2, data2, df2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph()\n",
    "\n",
    "# Define nodes\n",
    "dot.node('A', 'Node A')\n",
    "dot.node('B', 'Node B')\n",
    "dot.node('C', 'Node C')\n",
    "dot.node('D', 'Node D')\n",
    "\n",
    "# Define edges\n",
    "dot.edges(['AB', 'AC', 'BD', 'CD'])\n",
    "\n",
    "# Save and render the graph\n",
    "dot.render('graph', format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = contents.split('\\n')\n",
    "for c in content:\n",
    "    b = c.replace(\"    \", \"\\t\")\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_term_frequency(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    term_frequency = Counter(words)\n",
    "    \n",
    "    return term_frequency\n",
    "\n",
    "tf = calculate_term_frequency(text)\n",
    "sorted_tf = sorted(tf.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "for term, frequency in sorted_tf:\n",
    "    print(f\"{term}: {frequency}\")\n",
    "\n",
    "# Create histogram data\n",
    "frequency_count = Counter(tf.values())\n",
    "\n",
    "# Sort the frequency count by number of occurrences\n",
    "sorted_frequency_count = sorted(frequency_count.items())\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(21,9))\n",
    "bars = plt.bar([str(item[0]) for item in sorted_frequency_count], [item[1] for item in sorted_frequency_count])\n",
    "plt.bar([str(item[0]) for item in sorted_frequency_count], [item[1] for item in sorted_frequency_count])\n",
    "plt.xlabel('Number of Occurrences')\n",
    "plt.ylabel('Number of Words')\n",
    "plt.title('Word Frequency Histogram')\n",
    "# Add labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, int(yval), va='bottom') # va='bottom' to position the text below the bar edge\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math as m\n",
    "import numpy as np\n",
    "\n",
    "nnc = nn_contents.split('\\n')\n",
    "s_cnt = np.array([int(i.split()[-1]) for i in nnc])\n",
    "\n",
    "# print(s_cnt)\n",
    "print(f\"total #slides = {np.sum(s_cnt)}\\\n",
    "        \\ntotal #lectures = {len(s_cnt)}\\\n",
    "        \\navg #slides per lec = {int(np.ceil(np.mean(s_cnt)))}\\\n",
    "        \\nmin #slides = {np.min(s_cnt)}\\\n",
    "        \\nmax #slides = {np.max(s_cnt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory\n",
    "dls = r\"C:/Users/Siva/Downloads/Dua Lipa\"\n",
    "\n",
    "# List all files in the directory\n",
    "for filename in os.listdir(dls):\n",
    "    print(f\"Processing file: {filename}\")\n",
    "    \n",
    "    # Ensure the filename is long enough to contain a number and dot\n",
    "    if len(filename) > 3 and filename[:2].isdigit() and filename[2] == '.':\n",
    "        # Remove the number, dot, and any leading whitespace\n",
    "        new_name = filename[4:].strip()\n",
    "        \n",
    "        # Construct full file paths\n",
    "        old_file = os.path.join(dls, filename)\n",
    "        new_file = os.path.join(dls, new_name)\n",
    "        \n",
    "        # Check if the new file name already exists\n",
    "        if os.path.exists(new_file):\n",
    "            print(f\"Skipped: {new_name} already exists.\")\n",
    "        else:\n",
    "            # Rename the file\n",
    "            os.rename(old_file, new_file)\n",
    "            print(f\"Renamed: {filename} -> {new_name}\")\n",
    "    else:\n",
    "        print(f\"Skipped: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from mutagen import File\n",
    "\n",
    "# Specify the directory\n",
    "directory = r\"C:/Users/Siva/Downloads/Dua Lipa\"\n",
    "\n",
    "# List to hold details\n",
    "file_details = []\n",
    "\n",
    "# Iterate through the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    \n",
    "    # Check if it's a file (not a directory)\n",
    "    if os.path.isfile(file_path):\n",
    "        # Get file size in KB\n",
    "        file_size = os.path.getsize(file_path) / (1024)\n",
    "        \n",
    "        # Get file duration using mutagen\n",
    "        try:\n",
    "            audio = File(file_path)\n",
    "            duration = audio.info.length if audio and audio.info else None\n",
    "        except Exception as e:\n",
    "            duration = None\n",
    "            print(f\"Could not read duration for {filename}: {e}\")\n",
    "        \n",
    "        # Add details to the list\n",
    "        file_details.append({\n",
    "            \"File Name\": filename,\n",
    "            \"File Size (KB)\": round(file_size, 2),\n",
    "            \"Duration (s)\": round(duration, 2) if duration else \"Unknown\",\n",
    "            \"Duration(mm:ss)\": f\"{int(duration // 60)}:{int(duration % 60):02d}\" if duration else \"Unknown\"\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(file_details)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = os.path.join(directory, \"file_details.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Details saved to {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
